# -*- coding: utf-8 -*-
"""Copy of Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LPfMcEF4a5kYeEeJV0QKmKT6hETVaSA5
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

!kaggle datasets download -d redwankarimsony/heart-disease-data -p /content/heart-disease-data --unzip

import pandas as pd
df = pd.read_csv('/heart_disease_uci.csv')
print(df)

df.head()

df.isnull().sum()

numeric_cols = df.select_dtypes(include='number').columns
df[numeric_cols]=df[numeric_cols].fillna(df[numeric_cols].mean())

import matplotlib.pyplot as plt
import seaborn as sns
numeric_cols = df.select_dtypes(include='number').columns
df[numeric_cols]=df[numeric_cols].fillna(df[numeric_cols].mean())
df[numeric_cols].hist(figsize=(15,10))
plt.tight_layout()
plt.show()

sns.heatmap(df[numeric_cols].corr(),annot=True,cmap='coolwarm')
plt.title('Numeric feature Correlations')
plt.show()

import pandas as pd
df = pd.read_csv('/heart_disease_uci.csv')
cat_cols= df.select_dtypes(include='object').columns.tolist()
if 'num' in cat_cols:       # we are finding the text not numeric data columns
  cat_cols.remove('num')     #dont encode target column

x= df.drop('num',axis=1)
y= (df['num']>0).astype(int)    # 0 as no disease 1 disease present

x= pd.get_dummies(x,columns=cat_cols)
print("final feature columns",x.columns)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# x= pd.get_dummies(x,columns=cat_cols)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
# print("final feature columns",x.columns)

print(x_train.dtypes)

x_train = pd.get_dummies(x_train, drop_first=True)
x_test = pd.get_dummies(x_test, drop_first=True)

# Align train & test columns (important!)
x_train, x_test = x_train.align(x_test, join='left', axis=1, fill_value=0)

# Impute missing values after one-hot encoding
x_train = x_train.fillna(x_train.mean())
x_test = x_test.fillna(x_test.mean())

scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression() # giving addmission to a new student
lr_model.fit(x_train_scaled, y_train)    # trsining step

#    model evaliaton
from sklearn.metrics import accuracy_score, classification_report

y_pred_lr = lr_model.predict(x_test_scaled)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm,annot=True,fmt='d',cmap='Blues')
plt.title('Confusion Matrix (logistic Regression)')
plt.show()

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(x_train_scaled, y_train)
y_pred_rf = rf_model.predict(x_test_scaled)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))

import pandas as pd
feat_imp= pd.Series(rf_model.feature_importances_,index=x_train.columns)
feat_imp.nlargest(10).plot(kind='barh')
plt.title('random forest feature importance')
plt.show()

import joblib
joblib.dump(rf_model,'heart_rf_model.pkl')

joblib.dump(scaler,'heart_scaler.pkl')

sample =  x.head(1)
sample.to_csv('heart_user_template.csv',index = False)
print("user template saved as 'heart_user_template.csv' ")

import joblib
import pandas as pd
user_df = pd.read_csv('/content/heart-disease-data/heart_disease_uci.csv')

#getting columns list from training dataframe
numeric_cols = df.select_dtypes(include='number').columns.tolist()
cat_cols = df.select_dtypes(include='object').columns.tolist()
bool_cols = df.select_dtypes(include='bool').columns.tolist()


#dropping columns which are extra in user_df than required to avoid error
numeric_cols = [col for col in numeric_cols if col in user_df.columns]
cat_cols = [col for col in cat_cols if col in user_df.columns]
bool_cols = [col for col in bool_cols if col in user_df.columns]

#fill the missing numeric column & cat column
user_df[numeric_cols]= user_df[numeric_cols].fillna(user_df[numeric_cols].mean())
for col in cat_cols:
  user_df[col] = user_df[col].fillna('unknown')

for col in bool_cols:
  user_df[col]= user_df[col].astype(int)


#one-hot encoding cat columns
user_df_encoded = pd.get_dummies(user_df,columns = cat_cols)

#align columns
user_df_encoded = user_df_encoded.reindex(columns=x.columns,fill_value=0)

#scale data
scaler = joblib.load('heart_scaler.pkl')
user_df_scaled = scaler.transform(user_df_encoded)
#prediction part
model= joblib.load('heart_rf_model.pkl')
prediction = model.predict(user_df_scaled)
user_df['heart_disease_prediction'] =prediction
print(user_df)

